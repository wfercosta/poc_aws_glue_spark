{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+---------+-------+--------------------+----------+------+-------------+-------------------+\n",
      "|      date|     context|   family|version|            resource|  priority|status|response_time|          timestamp|\n",
      "+----------+------------+---------+-------+--------------------+----------+------+-------------+-------------------+\n",
      "|2021-12-25|open-banking| accounts|     v1|/accounts/v1/acco...|    MEDIUM|   200|          500|2021-12-25 13:50:36|\n",
      "|2021-12-25|open-banking| accounts|     v1|/accounts/v1/acco...|    MEDIUM|   500|          500|2021-12-25 13:51:36|\n",
      "|2021-12-25|open-banking| accounts|     v1|/accounts/v1/acco...|    MEDIUM|   500|          500|2021-12-25 13:52:36|\n",
      "|2021-12-25|open-banking| accounts|     v1|/accounts/v1/acco...|    MEDIUM|   500|          500|2021-12-25 13:53:36|\n",
      "|2021-12-25|open-banking| accounts|     v1|/accounts/v1/acco...|    MEDIUM|   200|          500|2021-12-25 13:54:36|\n",
      "|2021-12-25|open-banking| accounts|     v1|/accounts/v1/acco...|    MEDIUM|   200|          500|2021-12-25 13:55:36|\n",
      "|2021-12-25|open-banking| accounts|     v1|/accounts/v1/acco...|    MEDIUM|   200|          500|2021-12-25 13:56:36|\n",
      "|2021-12-25|open-banking|discovery|     v1|/discovery/v1/status|      HIGH|   200|          500|2021-12-25 13:50:36|\n",
      "|2021-12-25|open-banking|discovery|     v1|/discovery/v1/status|      HIGH|   500|          500|2021-12-25 13:51:36|\n",
      "|2021-12-25|open-banking|discovery|     v1|/discovery/v1/status|      HIGH|   500|          500|2021-12-25 13:52:36|\n",
      "|2021-12-25|open-banking|discovery|     v1|/discovery/v1/status|      HIGH|   500|          500|2021-12-25 13:53:36|\n",
      "|2021-12-25|open-banking|discovery|     v1|/discovery/v1/status|      HIGH|   200|          500|2021-12-25 13:54:36|\n",
      "|2021-12-25|open-banking|discovery|     v1|/discovery/v1/status|      HIGH|   200|          500|2021-12-25 13:55:36|\n",
      "|2021-12-25|open-banking|discovery|     v1|/discovery/v1/status|      HIGH|   200|          500|2021-12-25 13:56:36|\n",
      "|2021-12-25|open-banking|    admin|     v1|   /admin/v1/metrics|UNATTENDED|   200|          500|2021-12-25 13:50:36|\n",
      "|2021-12-25|open-banking|    admin|     v1|   /admin/v1/metrics|UNATTENDED|   500|          500|2021-12-25 13:51:36|\n",
      "|2021-12-25|open-banking|    admin|     v1|   /admin/v1/metrics|UNATTENDED|   500|          500|2021-12-25 13:52:36|\n",
      "|2021-12-25|open-banking|    admin|     v1|   /admin/v1/metrics|UNATTENDED|   500|          500|2021-12-25 13:53:36|\n",
      "|2021-12-25|open-banking|    admin|     v1|   /admin/v1/metrics|UNATTENDED|   200|          500|2021-12-25 13:54:36|\n",
      "|2021-12-25|open-banking|    admin|     v1|   /admin/v1/metrics|UNATTENDED|   200|          500|2021-12-25 13:55:36|\n",
      "+----------+------------+---------+-------+--------------------+----------+------+-------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- date: date (nullable = true)\n",
      " |-- context: string (nullable = true)\n",
      " |-- family: string (nullable = true)\n",
      " |-- version: string (nullable = true)\n",
      " |-- resource: string (nullable = true)\n",
      " |-- priority: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- response_time: integer (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from awsglue.context import GlueContext\n",
    "\n",
    "gc = GlueContext(SparkContext.getOrCreate())\n",
    "\n",
    "ddf = gc.create_dynamic_frame_from_options(\"s3\"\\\n",
    "                                          , {\"paths\": [\"s3://wfercosta-spark/DAILY_20211225.csv\"]}\\\n",
    "                                          ,\"csv\"\\\n",
    "                                          ,{'withHeader':True})\n",
    "        \n",
    "df = ddf.toDF()\n",
    "df = df.select(['date', 'context', 'family', 'version', 'resource'\\\n",
    "                , 'priority', 'status', 'response_time', 'timestamp'])\n",
    "\n",
    "df = df.withColumn('date', F.to_date(df.date))\n",
    "df = df.withColumn('timestamp', F.to_timestamp(df.timestamp))\n",
    "df = df.withColumn('response_time', df.response_time.cast('int'))\n",
    "\n",
    "df.show()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f85614f2b9b4441bb6e1ebb6252b39e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#For each endpoint in day and by context\n",
    "# date, context, family, version, resource, priority, total_downtime_sec, total_uptime_rate\n",
    "\n",
    "df_aval = df\n",
    "\n",
    "#Replicates the columns unneeded and replicates prev rows values on next\n",
    "column_list = ['date', 'context', 'resource']\n",
    "\n",
    "window = Window().partitionBy([F.col(x) for x in column_list]).orderBy([\\\n",
    "                                                                        F.col('resource')\\\n",
    "                                                                        , F.col('timestamp')])\n",
    "\n",
    "df_aval = df_aval.withColumn('status_prev', F.lag('status').over(window))\n",
    "\n",
    "#Filters intermediate row that is not a state transition\n",
    "df_aval = df_aval.filter(df_aval.status_prev.isNull() \\\n",
    "                                | (df_aval.status_prev != df_aval.status))\n",
    "\n",
    "df_aval = df_aval.withColumn(\"timestamp_prev\", F.lag(\"timestamp\").over(window))\n",
    "df_aval = df_aval.withColumn(\"timestamp_prev\", F.coalesce(df_aval.timestamp_prev, df_aval.timestamp)) \n",
    "\n",
    "df_aval = df_aval.filter(df_aval.status_prev.isNull() \\\n",
    "                         | ((df_aval.status >= 200) & (df_aval.status < 300)) \\\n",
    "                         | ((df_aval.status >= 400) & (df_aval.status < 500)))\n",
    "\n",
    "\n",
    "# Calculates the downtime in seconds\n",
    "df_aval = df_aval.withColumn('total_downtime_sec'\\\n",
    "                             , F.col('timestamp').cast('long') - F.col('timestamp_prev').cast('long'))\n",
    "\n",
    "df_aval = df_aval.groupby(['date', 'context'\\\n",
    "                , 'family', 'version'\\\n",
    "                , 'resource', 'priority'])\\\n",
    "                    .agg(\\\n",
    "                         F.sum('total_downtime_sec').alias('total_downtime_sec'))\n",
    "\n",
    "\n",
    "# Calculates the uptime rate \n",
    "calculate_uptime_rate = lambda downtime_sec: (((24 * 60 * 60) - downtime_sec)/(24 * 60 * 60))\n",
    "\n",
    "df_aval = df_aval.withColumn('total_uptime_rate', calculate_uptime_rate(df_aval.total_downtime_sec))\n",
    "df_aval = df_aval.withColumn('total_uptime_rate', F.round(df_aval.total_uptime_rate, 3))\n",
    "\n",
    "# Missing calculation\n",
    "df_aval = df_gen.withColumn('total_scheduled_outage', F.lit(0))\n",
    "\n",
    "df_aval.show()\n",
    "df_aval.printSchema()\n",
    "\n",
    "print(json.dumps(df_aval.toJSON().map(lambda j: json.loads(j)).collect(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General in a day and context\n",
    "# date, context, avg_tps, peak_tps, total_nr_rejections, total_nr_errors, total_uptime_rate, total_downtime_sec, total_scheduled_outage\n",
    "\n",
    "df_gen = df\n",
    "\n",
    "# Calculates the right time interval for each row\n",
    "calculate_interval = lambda field: (F.round(field.cast('long') / 60) * 60.0)\\\n",
    "                        .cast(\"timestamp\")\n",
    "\n",
    "df_gen = df_gen.withColumn('timestamp_intvl_1_min', calculate_interval(df_gen.timestamp))\n",
    "\n",
    "\n",
    "count_if = lambda condition: F.sum(F.when(condition, 1).otherwise(0))\n",
    "\n",
    "\n",
    "df_gen = df_gen.groupby(['date', 'context', 'timestamp_intvl_1_min'])\\\n",
    "            .agg(\\\n",
    "                 F.count(F.lit(1)).alias('tpm')\\\n",
    "                 , count_if(F.col('status') == 429).alias('total_nr_rejections') \\\n",
    "                 , count_if(F.col('status') > 500).alias('total_nr_errors'))\n",
    "\n",
    "\n",
    "df_gen = df_gen.withColumn('avg_tps', F.round(df_gen.tpm / 60, 3))\n",
    "\n",
    "\n",
    "df_gen = df_gen.groupby(['date', 'context'])\\\n",
    "            .agg(\\\n",
    "                   F.round(F.avg('avg_tps'), 3).alias('avg_tps')\\\n",
    "                 , F.round(F.max('avg_tps'), 3).alias('peak_tps')\\\n",
    "                 , F.sum('total_nr_rejections').alias('total_nr_rejections')\\\n",
    "                 , F.sum('total_nr_errors').alias('total_nr_errors'))\n",
    "\n",
    "\n",
    "df_gen_aval = df_aval.groupby(['date', 'context'])\\\n",
    "            .agg(\\\n",
    "                  F.sum('total_downtime_sec').alias('total_downtime_sec')\\\n",
    "                , F.sum('total_uptime_rate').alias('total_uptime_rate')\\\n",
    "                , F.sum('total_scheduled_outage').alias('total_scheduled_outage'))\n",
    "\n",
    "\n",
    "df_gen = df_gen.join(df_gen_aval, ['date', 'context'])\n",
    "\n",
    "\n",
    "df_gen.show()\n",
    "df_gen.printSchema()\n",
    "\n",
    "print(json.dumps(df_gen.toJSON().map(lambda j: json.loads(j)).collect(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General in a day and by Priority and context\n",
    "# date, context, priority, total_nr_invocations, avg_response\n",
    "\n",
    "df_gen_pri = df.groupby(['date', 'context', 'priority'])\\\n",
    "                .agg(\\\n",
    "                       F.count(F.lit(1)).alias('total_nr_invocations')\\\n",
    "                     , F.avg('response_time').alias('avg_response'))\n",
    "\n",
    "df_gen_pri.show()\n",
    "df_gen_pri.printSchema()\n",
    "\n",
    "\n",
    "print(json.dumps(df_gen_pri.toJSON().map(lambda j: json.loads(j)).collect(), indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
