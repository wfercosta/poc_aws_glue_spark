{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>0</td><td>None</td><td>pyspark</td><td>idle</td><td></td><td></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+---------+-------+--------------------+----------+------+-------------+-------------------+\n",
      "|      date|     context|   family|version|            resource|  priority|status|response_time|          timestamp|\n",
      "+----------+------------+---------+-------+--------------------+----------+------+-------------+-------------------+\n",
      "|2021-12-25|open-banking| accounts|     v1|/accounts/v1/acco...|    MEDIUM|   200|          500|2021-12-25 13:50:36|\n",
      "|2021-12-25|open-banking| accounts|     v1|/accounts/v1/acco...|    MEDIUM|   500|          500|2021-12-25 13:51:36|\n",
      "|2021-12-25|open-banking| accounts|     v1|/accounts/v1/acco...|    MEDIUM|   500|          500|2021-12-25 13:52:36|\n",
      "|2021-12-25|open-banking| accounts|     v1|/accounts/v1/acco...|    MEDIUM|   500|          500|2021-12-25 13:53:36|\n",
      "|2021-12-25|open-banking| accounts|     v1|/accounts/v1/acco...|    MEDIUM|   200|          500|2021-12-25 13:54:36|\n",
      "|2021-12-25|open-banking| accounts|     v1|/accounts/v1/acco...|    MEDIUM|   200|          500|2021-12-25 13:55:36|\n",
      "|2021-12-25|open-banking| accounts|     v1|/accounts/v1/acco...|    MEDIUM|   200|          500|2021-12-25 13:56:36|\n",
      "|2021-12-25|open-banking|discovery|     v1|/discovery/v1/status|      HIGH|   200|          500|2021-12-25 13:50:36|\n",
      "|2021-12-25|open-banking|discovery|     v1|/discovery/v1/status|      HIGH|   500|          500|2021-12-25 13:51:36|\n",
      "|2021-12-25|open-banking|discovery|     v1|/discovery/v1/status|      HIGH|   500|          500|2021-12-25 13:52:36|\n",
      "|2021-12-25|open-banking|discovery|     v1|/discovery/v1/status|      HIGH|   500|          500|2021-12-25 13:53:36|\n",
      "|2021-12-25|open-banking|discovery|     v1|/discovery/v1/status|      HIGH|   200|          500|2021-12-25 13:54:36|\n",
      "|2021-12-25|open-banking|discovery|     v1|/discovery/v1/status|      HIGH|   200|          500|2021-12-25 13:55:36|\n",
      "|2021-12-25|open-banking|discovery|     v1|/discovery/v1/status|      HIGH|   200|          500|2021-12-25 13:56:36|\n",
      "|2021-12-25|open-banking|    admin|     v1|   /admin/v1/metrics|UNATTENDED|   200|          500|2021-12-25 13:50:36|\n",
      "|2021-12-25|open-banking|    admin|     v1|   /admin/v1/metrics|UNATTENDED|   500|          500|2021-12-25 13:51:36|\n",
      "|2021-12-25|open-banking|    admin|     v1|   /admin/v1/metrics|UNATTENDED|   500|          500|2021-12-25 13:52:36|\n",
      "|2021-12-25|open-banking|    admin|     v1|   /admin/v1/metrics|UNATTENDED|   500|          500|2021-12-25 13:53:36|\n",
      "|2021-12-25|open-banking|    admin|     v1|   /admin/v1/metrics|UNATTENDED|   200|          500|2021-12-25 13:54:36|\n",
      "|2021-12-25|open-banking|    admin|     v1|   /admin/v1/metrics|UNATTENDED|   200|          500|2021-12-25 13:55:36|\n",
      "+----------+------------+---------+-------+--------------------+----------+------+-------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- date: date (nullable = true)\n",
      " |-- context: string (nullable = true)\n",
      " |-- family: string (nullable = true)\n",
      " |-- version: string (nullable = true)\n",
      " |-- resource: string (nullable = true)\n",
      " |-- priority: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- response_time: integer (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from awsglue.context import GlueContext\n",
    "\n",
    "gc = GlueContext(SparkContext.getOrCreate()) \n",
    "# df = gc.create_dynamic_frame_from_options(connection_type = \"s3\"\\\n",
    "#                                           , connection_options = {\"paths\": [\"s3://wfercosta-spark/logs.csv\"]}\\\n",
    "#                                           , format = \"csv\"\\\n",
    "#                                           , {'withHeader': True})\n",
    "\n",
    "ddf = gc.create_dynamic_frame_from_options(\"s3\"\\\n",
    "                                          , {\"paths\": [\"s3://wfercosta-spark/DAILY_20211225.csv\"]}\\\n",
    "                                          ,\"csv\"\\\n",
    "                                          ,{'withHeader':True})\n",
    "        \n",
    "df = ddf.toDF()\n",
    "df = df.select(['date', 'context', 'family', 'version', 'resource'\\\n",
    "                , 'priority', 'status', 'response_time', 'timestamp'])\n",
    "\n",
    "df = df.withColumn('date', F.to_date(df.date))\n",
    "df = df.withColumn('timestamp', F.to_timestamp(df.timestamp))\n",
    "df = df.withColumn('response_time', df.response_time.cast('int'))\n",
    "\n",
    "df.show()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+---------+-------+--------------------+----------+------------------+-----------------+\n",
      "|      date|       context|   family|version|            resource|  priority|total_downtime_sec|total_uptime_rate|\n",
      "+----------+--------------+---------+-------+--------------------+----------+------------------+-----------------+\n",
      "|2021-12-26|  open-banking| accounts|     v1|/accounts/v1/acco...|    MEDIUM|                 0|              1.0|\n",
      "|2021-12-25|open-insurance| accounts|     v1|/accounts/v1/acco...|    MEDIUM|               180|            0.998|\n",
      "|2021-12-25|  open-banking|    admin|     v1|   /admin/v1/metrics|UNATTENDED|               180|            0.998|\n",
      "|2021-12-25|  open-banking|discovery|     v1|/discovery/v1/status|      HIGH|               180|            0.998|\n",
      "|2021-12-25|open-insurance|    admin|     v1|   /admin/v1/metrics|UNATTENDED|               180|            0.998|\n",
      "|2021-12-25|open-insurance|discovery|     v1|/discovery/v1/status|      HIGH|               180|            0.998|\n",
      "|2021-12-25|  open-banking| accounts|     v1|/accounts/v1/acco...|    MEDIUM|               180|            0.998|\n",
      "+----------+--------------+---------+-------+--------------------+----------+------------------+-----------------+"
     ]
    }
   ],
   "source": [
    "#For each endpoint in day and by context\n",
    "# date, context, family, version, resource, priority, total_downtime_sec, total_uptime_rate\n",
    "\n",
    "df_aval = df\n",
    "\n",
    "#Replicates the columns unneeded and replicates prev rows values on next\n",
    "column_list = ['date', 'context', 'resource']\n",
    "\n",
    "window = Window().partitionBy([F.col(x) for x in column_list]).orderBy([\\\n",
    "                                                                        F.col('resource')\\\n",
    "                                                                        , F.col('timestamp')])\n",
    "\n",
    "df_aval = df_aval.withColumn('status_prev', F.lag('status').over(window))\n",
    "\n",
    "#Filters intermediate row that is not a state transition\n",
    "df_aval = df_aval.filter(df_aval.status_prev.isNull() \\\n",
    "                                | (df_aval.status_prev != df_aval.status))\n",
    "\n",
    "df_aval = df_aval.withColumn(\"timestamp_prev\", F.lag(\"timestamp\").over(window))\n",
    "df_aval = df_aval.withColumn(\"timestamp_prev\", F.coalesce(df_aval.timestamp_prev, df_aval.timestamp)) \n",
    "\n",
    "df_aval = df_aval.filter(df_aval.status_prev.isNull() \\\n",
    "                         | ((df_aval.status >= 200) & (df_aval.status < 300)) \\\n",
    "                         | ((df_aval.status >= 400) & (df_aval.status < 500)))\n",
    "\n",
    "\n",
    "# Calculates the downtime in seconds\n",
    "df_aval = df_aval.withColumn('total_downtime_sec'\\\n",
    "                             , F.col('timestamp').cast('long') - F.col('timestamp_prev').cast('long'))\n",
    "\n",
    "df_aval = df_aval.groupby(['date', 'context'\\\n",
    "                , 'family', 'version'\\\n",
    "                , 'resource', 'priority'])\\\n",
    "                    .agg(\\\n",
    "                         F.sum('total_downtime_sec').alias('total_downtime_sec'))\n",
    "\n",
    "\n",
    "# Calculates the uptime rate \n",
    "calculate_uptime_rate = lambda downtime_sec: (((24 * 60 * 60) - downtime_sec)/(24 * 60 * 60))\n",
    "\n",
    "df_aval = df_aval.withColumn('total_uptime_rate', calculate_uptime_rate(df_aval.total_downtime_sec))\n",
    "df_aval = df_aval.withColumn('total_uptime_rate', F.round(df_aval.total_uptime_rate, 3))\n",
    "\n",
    "\n",
    "df_aval.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+-------+--------+-------------------+---------------+------------------+------------------+\n",
      "|      date|       context|avg_tps|peak_tps|total_nr_rejections|total_nr_errors|total_downtime_sec| total_uptime_rate|\n",
      "+----------+--------------+-------+--------+-------------------+---------------+------------------+------------------+\n",
      "|2021-12-26|  open-banking|  0.017|   0.017|                  0|              0|                 0|               1.0|\n",
      "|2021-12-25|  open-banking|   0.05|    0.05|                  0|              0|               540|2.9939999999999998|\n",
      "|2021-12-25|open-insurance|   0.05|    0.05|                  0|              0|               540|2.9939999999999998|\n",
      "+----------+--------------+-------+--------+-------------------+---------------+------------------+------------------+"
     ]
    }
   ],
   "source": [
    "# General in a day and context\n",
    "# date, context, avg_tps, peak_tps, total_nr_rejections, total_nr_errors, total_uptime_rate, total_downtime_sec, total_scheduled_outage\n",
    "\n",
    "#df.groupby('context', 'resource').agg(min(df.latency), max(df.latency), avg(df.latency)).show()\n",
    "\n",
    "# df_final = df.groupby('contex', 'family', 'version', 'resource').agg()\n",
    "\n",
    "# df_final.show()\n",
    "\n",
    "df_gen = df\n",
    "\n",
    "# Calculates the right time interval for each row\n",
    "calculate_interval = lambda field: (F.round(field.cast('long') / 60) * 60.0)\\\n",
    "                        .cast(\"timestamp\")\n",
    "\n",
    "df_gen = df_gen.withColumn('timestamp_intvl_1_min', calculate_interval(df_gen.timestamp))\n",
    "\n",
    "\n",
    "count_if = lambda condition: F.sum(F.when(condition, 1).otherwise(0))\n",
    "\n",
    "\n",
    "df_gen = df_gen.groupby(['date', 'context', 'timestamp_intvl_1_min'])\\\n",
    "            .agg(\\\n",
    "                 F.count(F.lit(1)).alias('tpm')\\\n",
    "                 , count_if(F.col('status') == 429).alias('total_nr_rejections') \\\n",
    "                 , count_if(F.col('status') > 500).alias('total_nr_errors'))\n",
    "\n",
    "\n",
    "df_gen = df_gen.withColumn('avg_tps', F.round(df_gen.tpm / 60, 3))\n",
    "\n",
    "\n",
    "df_gen = df_gen.groupby(['date', 'context'])\\\n",
    "            .agg(\\\n",
    "                   F.round(F.avg('avg_tps'), 3).alias('avg_tps')\\\n",
    "                 , F.round(F.max('avg_tps'), 3).alias('peak_tps')\\\n",
    "                 , F.sum('total_nr_rejections').alias('total_nr_rejections')\\\n",
    "                 , F.sum('total_nr_errors').alias('total_nr_errors'))\n",
    "\n",
    "\n",
    "df_gen_aval = df_aval.groupby(['date', 'context'])\\\n",
    "            .agg(\\\n",
    "                  F.sum('total_downtime_sec').alias('total_downtime_sec')\n",
    "                , F.sum('total_uptime_rate').alias('total_uptime_rate'))\n",
    "\n",
    "\n",
    "df_gen = df_gen.join(df_gen_aval, ['date', 'context'])\n",
    "\n",
    "df_gen.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gneral in a day and by Priority and context\n",
    "# date, context, priority, total_nr_invocations, avg_response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
